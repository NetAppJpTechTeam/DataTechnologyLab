=============================================================
実践編: 画像解析AIを作成を体験
=============================================================

はじめに
=============================================================

Kubernetes上でAIアプリケーションを作成するハンズオンです。

ハンズオンの流れ
=============================================================

* 当日の環境確認
* (Optional) 手順に従って kubeflow をデプロイ
    *　イベントでは事前デプロイ
* デプロイした環境を触ってなれる
    * JupyterNotebookなどを触る（手順を含んでいるノートブックのインポート）
    * Pythonのコードから実際に学習をしてみる。
* トレーニングデータの準備、自分用のデータを準備(Cloneをすることをイメージしている）
* サンプルの学習コードを使ってモデル作成ー＞成果物はObject or ファイルサーバ
* アプリケーションから利用する。コンテナイメージを作成する。
* イメージをレジストリ登録する。
* Service, Deploymentを準備してデプロイ
* 画像をアップロードして動作確認する。
* Kubernetes上でAIアプリケーションを作成
* データサイエンスワークフロー
    * 精度を確認して、改善のフェーズへ。

デプロイ後の流れ/フィードバックを回す
=============================================================

* データの可視化 Jupyter使ってデータの分布等をみて最初のトレーニングデータのデータの偏り等を確認
* パラメータの変更点を伝えて実際にどれほど精度が変わるか試してみる
* トレーニングを実施、モデルを作成する
* 作成したモデルを別バージョンのコンテナとする
* k8s上に前述とは違うバージョンとしてデプロイする

* Istio使ってトラフィックマネージメントをしてみる。
    * A/Bテストとして使う
    * URL変更でバージョンを変える
    * ユーザでバージョンを変える

改善サイクルフェーズアプリケーションの変更ではなく
学習データモデルを変えることで改善することを確認する。

キーワードとしては以下のキーワードがあり、キーワードを交えて、理解してもらうのがゴール。

* Over fitting
* Cross validation

.. todo:: クロスバリデーション

たくさん流してオンプレミスのGPUが枯渇したら？

GCP の使い方考察
======================================================

シナリオ
--------------

* GCPのインターコネクトでNPS上のトレーニングデータを準備
* k8sクラスタは１つでGPUノードを複数準備
* ユーザー分離はClusterRoleとClusterRoleBindingで実施
* ResourceQuotaをnamespace設定し使いすぎ予防
* config で切り替えてオンプレ・クラウドのGPUを使用する。
* kubeflowはnamespace単位でデプロイするかも。
* inferenceだけをやるのもあり。
* デプロイはデモで見せる。(NKS)

準備物
--------------

.. todo:: kubernetes用コンフィグを都合３つ準備（オンプレ、GPU、GCP）
.. todo:: namespaceで分離 = 参加者分
.. todo:: CrusterRoleBindings = namespace を付与する。
.. todo:: Registryを創る（オンプレ：Harbor, クラウド: GCR)
.. todo:: クライアントからのe2eのシナリオ追加、モバイルアプリからデータ投入、インファレンスまで