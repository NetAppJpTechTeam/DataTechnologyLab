.. index::
    single:

.. raw::html

=============================================================
実践編: 画像解析AIを作成を体験
=============================================================

はじめに
=============================================================

Kubernetes上でAIアプリケーションを作成するハンズオンです。

ハンズオンの流れ
=============================================================

* 当日の環境確認
* (Optional) 手順に従って kubeflow をデプロイ
* デプロイした環境を触ってなれる
    * JupyterNotebookなどを触る（手順を含んでいるノートブックのインポート）
    * Pythonのコードから実際に学習をしてみる。
* トレーニングデータの準備、自分用のデータを準備(Cloneをすることをイメージしている）
* サンプルの学習コードを使ってモデル作成ー＞Object or ファイルサーバ
* アプリケーションに含み、コンテナイメージを作成
* イメージをレジストリ登録
* サンプルのService, Deployment, を準備してデプロイ
* 画像をアップロードして動作確認
* 精度を確認して、次へ。
* Kubernetes上でAIアプリケーションを作成
* データサイエンスワークフロー

デプロイ後の流れ/フィードバックを回す
=============================================================

* データの可視化 Jupyter使ってデータの分布等をみて最初のトレーニングデータのデータの偏り等を確認
* パラメータの変更点を伝えて実際に変更してもらう。
* トレーニングを実施、モデルを作成
* 作成したモデルを別バージョンのコンテナとする
* k8s上に前述とは違うバージョンとしてデプロイする。

* Istio使ってトラフィックマネージメントをしてみる。
* A/Bテストとして使う
* URL変更でバージョンを変える
* ユーザでバージョンを変える

改善サイクルフェーズアプリケーションの変更ではなく
学習データモデルを変えることで改善することを確認する。

キーワードとしては以下のキーワードがデてきます。
キーワードも交える・理解してもらう。

* Over fitting
* Cross validation

.. todo:: クロスバリデーション

GPUが枯渇したら？


GCP の使い方考察
======================================================

シナリオ
--------------

* GCPのインターコネクトでNPS上のトレーニングデータを準備
* k8s クラスタは１つでGPUノードを複数準備
* ユーザー分離はClusterRoleとClusterRoleBindingで実施
* ResourceQuotaをnamespace設定し使いすぎ予防
* config で切り替えてオンプレ・クラウドのGPUを使用する。
* kubeflowはnamespace単位でデプロイするかも。
* inferenceだけをやるのもあり。
* デプロイはデモで見せる。(NKS)

準備物
--------------
.. todo:: kubernetes用コンフィグを都合３つ準備（オンプレ、GPU、GCP）
.. todo:: namespaceで分離 = 参加者分
.. todo:: CrusterRoleBindings = namespace を付与する。
.. todo:: NPS with GCP
.. todo::　専用線構築
.. todo:: Registryを創る（オンプレ：Harbor, クラウド: GCR)
